{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "import re\n",
        "\n",
        "# Load the full PDF\n",
        "pdf_path = \"/content/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\n",
        "reader = PdfReader(pdf_path)\n",
        "\n",
        "# Combine all text for processing\n",
        "all_text = \"\"\n",
        "for page in reader.pages:\n",
        "    all_text += page.extract_text() + \"\\n\"\n",
        "\n",
        "# Define regex pattern to extract tabular data\n",
        "line_item_pattern = re.compile(\n",
        "    r\"(?P<description>.+?)\\s+(?P<quantity>\\d+\\.\\d{2})\\s+(?P<unit>[A-Z]+)\\s+\"\n",
        "    r\"(?P<tax>\\d+\\.\\d{2})\\s+(?P<op>\\d+\\.\\d{2})\\s+(?P<rcv>\\d+\\.\\d{2})\\s+\"\n",
        "    r\"(?P<age_life>\\d+\\/(?:\\d+|NA)[^\\s]*)\\s+(?P<cond>Avg\\.)\\s+\"\n",
        "    r\"(?P<dep_pct>\\d+\\.?\\d*%)\\s+\\((?P<deprec>\\d+\\.\\d{2})\\)\\s+(?P<acv>\\d+\\.\\d{2})\"\n",
        ")\n",
        "\n",
        "# Extract all matches\n",
        "matches = list(line_item_pattern.finditer(all_text))\n",
        "\n",
        "# Build JSON-like structure\n",
        "records = []\n",
        "for idx, match in enumerate(matches, 1):\n",
        "    groups = match.groupdict()\n",
        "    record = {\n",
        "        \"Serial\": idx,\n",
        "        \"Description\": groups[\"description\"].strip(),\n",
        "        \"Quantity\": float(groups[\"quantity\"]),\n",
        "        \"Unit\": groups[\"unit\"],\n",
        "        \"Tax\": float(groups[\"tax\"]),\n",
        "        \"O&P\": float(groups[\"op\"]),\n",
        "        \"RCV\": float(groups[\"rcv\"]),\n",
        "        \"Age/Life\": groups[\"age_life\"],\n",
        "        \"Cond.\": groups[\"cond\"],\n",
        "        \"Dep%\": groups[\"dep_pct\"],\n",
        "        \"Deprec.\": float(groups[\"deprec\"]),\n",
        "        \"ACV\": float(groups[\"acv\"])\n",
        "    }\n",
        "    records.append(record)\n",
        "\n",
        "#records[:5]  # Show sample of first 5 items\n"
      ],
      "metadata": {
        "id": "TFPWFn8ANiKQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from trp.t_pipeline import pipeline_merge_tables\n",
        "import trp.trp2 as t2\n",
        "from textractcaller.t_call import call_textract, Textract_Features\n",
        "from textractprettyprinter.t_pretty_print import Textract_Pretty_Print, get_string, get_tables_string, Pretty_Print_Table_Format\n",
        "from trp.trp2 import TDocument, TDocumentSchema\n",
        "from trp.t_tables import MergeOptions, HeaderFooterType\n",
        "import boto3\n",
        "import fitz\n",
        "import pandas as pd\n",
        "from trp import Document\n",
        "from textractprettyprinter.t_pretty_print import convert_table_to_list\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "textract_client = boto3.client('textract', region_name='region',aws_access_key_id='', aws_secret_access_key='')\n",
        "\n",
        "\n",
        "\n",
        "import boto3\n",
        "s3bucket = boto3.resource(service_name='s3', region_name='ap-south-1', aws_access_key_id='', aws_secret_access_key='')\n",
        "\n",
        "#Filename = \"D:\\\\downloads\\Working PDF Files\\\\Working PDF Files\\\\1. CIC insurance\\\\extracted_FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\n",
        "Filename=\"/content/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\n",
        "key = \"FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\n",
        "s3bucket.Bucket('awstextractpdfuploads').upload_file(Filename=Filename, Key=key)\n",
        "\n",
        "s3_uri_of_documents = \"s3://awstextractpdfuploads/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\n",
        "textract_json_cic_full_insurance = call_textract(input_document=s3_uri_of_documents, features=[Textract_Features.TABLES], boto3_textract_client = textract_client)\n",
        "\n",
        "# use this textract_json_cic_full_insurance object in code\n",
        "\n",
        "\n",
        "\n",
        "import traceback\n",
        "import json\n",
        "\n",
        "\n",
        "def allowed_file(filename):\n",
        "    ALLOWED_EXTENSIONS = {'pdf'}\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def remove_leading_numbers(text):\n",
        "    return re.sub(r'^\\d+\\.\\s*', '', text)\n",
        "\n",
        "def extract_pages_with_keywords(directory_path, file_name, unique_no):\n",
        "    try:\n",
        "        # Define keyword groups\n",
        "\n",
        "        GROUP_1 = {\"Quantity\", \"QTY\", \"Measurement\"}\n",
        "        GROUP_2 = {\"Price\", \"Unit\", \"UNIT PRICE\", \"Replace\", \"Remove\"}\n",
        "        GROUP_3 = {\"Total\", \"Total Price\", \"RCV\", \"RC\"}\n",
        "\n",
        "        pdf_path = directory_path + file_name\n",
        "        doc = fitz.open(pdf_path)\n",
        "        selected_pages = []\n",
        "\n",
        "        # Check each page for the required keywords\n",
        "        for page_num in range(len(doc)):\n",
        "            text = doc[page_num].get_text(\"text\").lower()\n",
        "            if (any(kw.lower() in text for kw in GROUP_1) and\n",
        "                    any(kw.lower() in text for kw in GROUP_2) and\n",
        "                    any(kw.lower() in text for kw in GROUP_3)):\n",
        "                selected_pages.append(page_num + 1)  # Page numbers are 1-based\n",
        "                #print('#' * 100 + str(' page ') + str(page_num))\n",
        "        if not selected_pages:\n",
        "            print(\"No matching pages found.\")\n",
        "            return None\n",
        "\n",
        "        output_pdf_path = directory_path + str(unique_no) + '_' + file_name\n",
        "        new_doc = fitz.open()\n",
        "        #print(output_pdf_path)\n",
        "        for page_num in selected_pages:\n",
        "            new_doc.insert_pdf(doc, from_page=page_num - 1, to_page=page_num - 1)\n",
        "\n",
        "        new_doc.save(output_pdf_path)\n",
        "        new_doc.close()\n",
        "\n",
        "        print(f\"Extracted PDF saved as: {output_pdf_path}\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return output_pdf_path\n",
        "\n",
        "def merge_and_clean_data(data):\n",
        "    output = []\n",
        "    temp_desc = \"\"\n",
        "    temp_quantity = \"\"\n",
        "    last_valid_acv_item = None\n",
        "    try:\n",
        "        KEY_VARIANTS = {\n",
        "            'quantity': ['quantity', 'qty'],\n",
        "            'unit': ['unit', 'unit price'],\n",
        "            'tax': ['tax', 'tax percent', 'tax value']\n",
        "        }\n",
        "\n",
        "        def find_flexible_key(item, standard_key):\n",
        "            \"\"\"Find the key in `item` that matches any known variant for the given standard key.\"\"\"\n",
        "            variants = KEY_VARIANTS.get(standard_key, [])\n",
        "            for var in variants:\n",
        "                for key in item:\n",
        "                    if var.lower() in key.lower():\n",
        "                        return key\n",
        "            return None\n",
        "\n",
        "        #print('EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE')\n",
        "        #print(data)\n",
        "        #print('DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDd')\n",
        "        for item in data:\n",
        "            #print('########## '+ str(item))\n",
        "            if not item[\"ACV\"].strip():  # If ACV is empty\n",
        "                # Merge all non-empty values into DESCRIPTION\n",
        "                combined_text = \" \".join(v.strip() for k, v in item.items() if v.strip())\n",
        "                temp_desc += \" \" + combined_text if combined_text else \"\"\n",
        "                temp_desc = temp_desc.strip()\n",
        "            else:  # ACV exists\n",
        "                if temp_desc:  # Merge previous descriptions into this item\n",
        "                    item[\"DESCRIPTION\"] = temp_desc\n",
        "                    item[\"DESCRIPTION\"] = item[\"DESCRIPTION\"].strip()\n",
        "                    temp_desc = \"\"\n",
        "\n",
        "            if item[\"ACV\"].strip() or ('Total:' in item.get('QUANTITY', '') or 'Totals:' in item.get('QUANTITY', '')):\n",
        "                output.append(item)\n",
        "            last_valid_acv_item = item  # Update last valid ACV item\n",
        "\n",
        "            # Find flexible keys\n",
        "            '''qty_key = find_flexible_key(item, 'quantity')\n",
        "            unit_key = find_flexible_key(item, 'unit')\n",
        "            tax_key = find_flexible_key(item, 'tax')\n",
        "\n",
        "            qty_list = item.get(qty_key, '').split(' ') if qty_key else []\n",
        "            unit_list = item.get(unit_key, '').split(' ') if unit_key else []\n",
        "            tax_list = item.get(tax_key, '').split(' ') if tax_key else []\n",
        "\n",
        "\n",
        "            # Add leftover parts to DESCRIPTION\n",
        "            if len(qty_list) > 2:\n",
        "                item['DESCRIPTION'] += ' ' + ' '.join(qty_list[:-2])\n",
        "            if len(unit_list) > 1:\n",
        "                item['DESCRIPTION'] += ' ' + ' '.join(unit_list[:-1])\n",
        "            if len(tax_list) > 1:\n",
        "                item['DESCRIPTION'] += ' ' + ' '.join(tax_list[:-1])\n",
        "\n",
        "            item['DESCRIPTION'] = item['DESCRIPTION'].strip()'''\n",
        "\n",
        "            #print('$$$$$$$$$$$$$$$$$$$$$ '+ str(item))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def merge_entries(data):\n",
        "    merged_list = []\n",
        "    skip_next = False\n",
        "\n",
        "    for i in range(len(data) - 1):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "        try:\n",
        "            current = data[i]\n",
        "            next_entry = data[i + 1]\n",
        "            last_key = next(reversed(current))\n",
        "            # If the current entry has an empty ACV, merge its values into next entry's description\n",
        "            if not current[last_key]:\n",
        "                merged_description = \" \".join(filter(None, [current[key] for key in current]))  # Concatenate all values\n",
        "                merged_entry = next_entry.copy()\n",
        "                merged_entry['DESCRIPTION'] = merged_description\n",
        "\n",
        "                merged_list.append(merged_entry)\n",
        "                skip_next = True  # Skip the next entry since it's merged\n",
        "            else:\n",
        "                merged_list.append(current)\n",
        "        except:\n",
        "            pass\n",
        "    # Add the last entry if it wasn't merged\n",
        "    if not skip_next:\n",
        "        merged_list.append(data[-1])\n",
        "\n",
        "    return merged_list\n",
        "\n",
        "\n",
        "def clean_description(data):\n",
        "    try:\n",
        "        # Process each room in the data\n",
        "        quantity_keys = {\"QTY\", \"QUANTITY\", \"MEASUREMENT\"}\n",
        "\n",
        "        def find_QTY_key(d):\n",
        "            \"\"\"Find the key in the dictionary that matches QTY, QUANTITY, or MEASUREMENT.\"\"\"\n",
        "            for key in d:\n",
        "                if key.upper() in quantity_keys:\n",
        "                    return key\n",
        "            return None  # No matching key found\n",
        "\n",
        "        for room, items in data.items():\n",
        "            for item in items:\n",
        "                QTY_key = find_QTY_key(item.keys())\n",
        "                # Clean numbered descriptions\n",
        "                if \"DESCRIPTION\" in item:\n",
        "                    # Remove number prefix (e.g., \"20. \", \"21. \")\n",
        "                    if item[\"DESCRIPTION\"].strip():\n",
        "                        parts = item[\"DESCRIPTION\"].split(\".\")\n",
        "                        if len(parts) > 1 and parts[0].strip().isdigit():\n",
        "                            item[\"DESCRIPTION\"] = \".\".join(parts[1:]).strip()\n",
        "\n",
        "                # Handle empty descriptions with data in QUANTITY\n",
        "                if \"DESCRIPTION\" in item and not item[\"DESCRIPTION\"].strip() and QTY_key in item:\n",
        "                    quantity_parts = item[QTY_key].split()\n",
        "                    if len(quantity_parts) >= 2:\n",
        "                        # Extract description and quantity\n",
        "                        description_parts = []\n",
        "                        quantity_value = None\n",
        "                        unit = None\n",
        "\n",
        "                        for part in quantity_parts:\n",
        "                            if any(char.isdigit() for char in part):\n",
        "                                quantity_value = part\n",
        "                                if unit:\n",
        "                                    break\n",
        "                            else:\n",
        "                                if quantity_value:\n",
        "                                    unit = part\n",
        "                                else:\n",
        "                                    description_parts.append(part)\n",
        "\n",
        "                        if description_parts:\n",
        "                            item[\"DESCRIPTION\"] = \" \".join(description_parts)\n",
        "                            if quantity_value and unit:\n",
        "                                item[QTY_key] = f\"{quantity_value} {unit}\"\n",
        "\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "# Function to get unique keys from result 2 that aren't in result 1\n",
        "def compare_and_get_unique_keys(result1, result2):\n",
        "    result3 = {}\n",
        "    try:\n",
        "        key_map = {\n",
        "            \"quantity\": \"measurement\", \"qty\": \"measurement\", \"measurement\": \"measurement\",\n",
        "            \"price\": \"unit\", \"unit\": \"unit\", \"replace\": \"unit\", \"remove\": \"unit\", \"unit price\": \"unit\"\n",
        "        }\n",
        "\n",
        "        def normalize_key(key):\n",
        "            return key_map.get(key.lower(), key)  # Convert to lowercase and map if applicable\n",
        "\n",
        "        # Get all sections from result2\n",
        "        for section in result2.keys():\n",
        "            # Skip if section exists in result1\n",
        "            if section not in result1:\n",
        "                continue\n",
        "\n",
        "            existing_keys = [normalize_key(k) for k in result1[section][0].keys()]\n",
        "            # Get all unique keys from the items in this section\n",
        "            unique_keys = list()\n",
        "\n",
        "            for item in result2[section]:\n",
        "                for key in item.keys():\n",
        "                    norm_key = normalize_key(key)\n",
        "                    if norm_key not in existing_keys:\n",
        "                        if key not in unique_keys:\n",
        "                            unique_keys.append(key)\n",
        "\n",
        "            if unique_keys:\n",
        "                result3[section] = unique_keys\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return result3\n",
        "\n",
        "\n",
        "# Function to compare two JSONs dynamically based on the first key\n",
        "def compare_json(result_1, result_2):\n",
        "    output = {}\n",
        "    quantity_keys = {\"QTY\", \"QUANTITY\", \"MEASUREMENT\"}\n",
        "    keys_to_check = {\"PRICE\", \"UNIT\", \"REPLACE\"}  # Standardized keys\n",
        "\n",
        "    def find_quantity_key(d):\n",
        "        \"\"\"Find the key in the dictionary that matches QTY, QUANTITY, or MEASUREMENT.\"\"\"\n",
        "        for key in d:\n",
        "            if key.upper() in quantity_keys:\n",
        "                return key\n",
        "        return None  # No matching key found\n",
        "\n",
        "    def extract_float(value):\n",
        "        \"\"\"Extracts a float from a string if it contains a number, otherwise returns None.\"\"\"\n",
        "        if isinstance(value, (int, float)):\n",
        "            return float(value)  # Already a number\n",
        "        elif isinstance(value, str):\n",
        "            match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", value)  # Find numeric value\n",
        "            return float(match.group()) if match else None\n",
        "        return None  # If value is not a valid type\n",
        "\n",
        "    def find_unit_key(d):\n",
        "        \"\"\"Find a key that matches the defined set.\"\"\"\n",
        "        for key in d:\n",
        "            if key.upper() in keys_to_check:\n",
        "                return key\n",
        "        return None  # No matching key found\n",
        "    try:\n",
        "        for key_2, records_2 in result_2.items():\n",
        "            table_found = \"Yes\" if key_2 in result_1 else \"No\"\n",
        "            result_list = []\n",
        "\n",
        "            for record_2 in records_2:\n",
        "                try:\n",
        "                    record_2.update({\"STATUS\": {}})\n",
        "                    record_match = \"No\"\n",
        "\n",
        "                    first_key_2 = next(iter(record_2), None)\n",
        "                    first_value_2 = record_2[first_key_2] if first_key_2 else None\n",
        "\n",
        "                    # Check if the key exists in result_1\n",
        "                    if table_found == \"Yes\":\n",
        "                        # print(result_1[key_2])\n",
        "                        for record_1 in result_1[key_2]:\n",
        "                            # print(record_1.keys())\n",
        "                            first_key_1 = next(iter(record_1), None)  # Get first key dynamically\n",
        "                            first_value_1 = record_1[first_key_1] if first_key_1 else None\n",
        "\n",
        "                            # Compare first values\n",
        "                            if first_value_1 == first_value_2:\n",
        "                                key1 = find_quantity_key(record_1)\n",
        "                                key2 = find_quantity_key(record_2)\n",
        "\n",
        "                                fk1 = find_unit_key(record_1)\n",
        "                                fk2 = find_unit_key(record_2)\n",
        "\n",
        "                                record_match = \"Yes\"\n",
        "                                if key1 and key2:\n",
        "                                    value1, value2 = record_1[key1], record_2[key2]\n",
        "\n",
        "                                    if value1 == value2:\n",
        "                                        #print(f\"Values match: {value1}\")\n",
        "                                        record_2['STATUS'][key2] = 'Yes'\n",
        "                                    else:\n",
        "                                        record_2['STATUS'][key2] = 'No'\n",
        "                                        #print(f\"Values do not match: {value1} (dict1) vs {value2} (dict2)\")\n",
        "                                #else:\n",
        "                                #    print(\"No common quantity key found in both dictionaries.\")\n",
        "\n",
        "                                if fk1 and fk2:\n",
        "                                    if fk1 == 'REPLACE':\n",
        "                                        value1 = extract_float(record_1[fk1]) + extract_float(record_1['REMOVE'])\n",
        "                                        value2 = extract_float(record_2[fk2])\n",
        "                                    elif fk2 == 'REPLACE':\n",
        "                                        value1 = extract_float(record_1[fk1])\n",
        "                                        value2 = extract_float(record_2[fk2]) + extract_float(record_2['REMOVE'])\n",
        "                                    else:\n",
        "                                        value1, value2 = extract_float(record_1[fk1]), extract_float(record_2[fk2])\n",
        "\n",
        "                                    if value1 is None or value2 is None:\n",
        "                                        #print(\n",
        "                                        #    f\"Could not extract valid numbers: {dict1[fk1]} (dict1) vs {dict2[fk2]} (dict2)\")\n",
        "                                        if fk2 == 'REPLACE':\n",
        "                                            record_2['STATUS'][fk2] = 'No'\n",
        "                                            record_2['STATUS']['REMOVE'] = 'No'\n",
        "                                        else:\n",
        "                                            record_2['STATUS'][fk2] = 'No'\n",
        "                                    elif value1 == value2:\n",
        "                                        #print(f\"Values match: {value1}\")\n",
        "                                        record_2['STATUS'][fk2] = 'Yes'\n",
        "                                    #else:\n",
        "                                    #    print(f\"Values do not match: {value1} (dict1) vs {value2} (dict2)\")\n",
        "\n",
        "                                break  # Stop once a match is found\n",
        "\n",
        "                    # Add match results\n",
        "                    record_2['STATUS'][\"TABLE_MATCH\"] = table_found\n",
        "                    record_2['STATUS'][\"RECORD_MATCH\"] = record_match\n",
        "                    result_list.append(record_2)\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "\n",
        "            output[key_2] = result_list\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def remove_images_pdf(directoryPath, fileName):\n",
        "    try:\n",
        "        print(directoryPath)\n",
        "        pdf_path = directoryPath + fileName\n",
        "        print(pdf_path)\n",
        "        doc = fitz.open(pdf_path)\n",
        "        large_image_pages = []\n",
        "\n",
        "        # Minimum dimensions for what we consider a \"large\" image (in pixels)\n",
        "        MIN_WIDTH = 200\n",
        "        MIN_HEIGHT = 200\n",
        "\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            images = page.get_images(full=True)\n",
        "\n",
        "            for img_index, img in enumerate(images):\n",
        "                xref = img[0]\n",
        "                base_image = doc.extract_image(xref)\n",
        "\n",
        "                if base_image:\n",
        "                    # Get image dimensions\n",
        "                    width = base_image[\"width\"]\n",
        "                    height = base_image[\"height\"]\n",
        "\n",
        "                    # Check if image meets minimum size requirements\n",
        "                    if width >= MIN_WIDTH and height >= MIN_HEIGHT:\n",
        "                        large_image_pages.append(page_num + 1)  # Pages are 1-indexed\n",
        "                        break  # One large image is enough to mark the page\n",
        "\n",
        "        print(\"Pages with large images:\", large_image_pages)\n",
        "        output_pdf = directoryPath + \"extracted_\" + fileName\n",
        "\n",
        "        # Create new PDF without pages containing large images\n",
        "        doc = fitz.open(pdf_path)\n",
        "        doc.select([i for i in range(len(doc)) if (i + 1) not in large_image_pages])\n",
        "        doc.save(output_pdf)\n",
        "        doc.close()\n",
        "        print(f\"New PDF saved as {output_pdf}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return \"success\"\n",
        "\n",
        "def process_items_old(final_list):\n",
        "    processed_items = []\n",
        "    try:\n",
        "        quantity_pattern = re.compile(r'(?P<quantity>\\d+(?:\\.\\d+)?)\\s*(?P<unit>LF|SF|SQ|EA|HR)')\n",
        "        quantity_keys = {\"QTY\", \"QUANTITY\", \"MEASUREMENT\"}\n",
        "        def find_quantity_key(data):\n",
        "            for key in quantity_keys:\n",
        "                if key in data:\n",
        "                    return key  # Return the found key\n",
        "            return None\n",
        "\n",
        "        for items in final_list:\n",
        "            for item in items:\n",
        "                description = item.get(\"DESCRIPTION\", \"\").strip()\n",
        "                qty_key = find_quantity_key(item)\n",
        "                quantity = item.get(qty_key, \"\").strip()\n",
        "\n",
        "                match = quantity_pattern.search(quantity)\n",
        "                if match:\n",
        "                    extracted_quantity = match.group(\"quantity\") + \" \" + match.group(\"unit\")\n",
        "                    remaining_text = quantity.replace(match.group(0), \"\").strip()\n",
        "\n",
        "                    if not description:\n",
        "                        description = remaining_text\n",
        "                        quantity = extracted_quantity\n",
        "                    else:\n",
        "                        quantity = extracted_quantity\n",
        "                        description = description + \" \" + remaining_text if remaining_text else description\n",
        "\n",
        "                item[\"DESCRIPTION\"] = description\n",
        "                item[qty_key] = quantity\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return final_list\n",
        "\n",
        "def process_items(final_list):\n",
        "    processed_items = []\n",
        "    try:\n",
        "        quantity_pattern = re.compile(r'(?P<quantity>\\d+(?:\\.\\d+)?)\\s*(?P<unit>LF|SF|SQ|EA|HR)')\n",
        "\n",
        "        quantity_keys = {\"QTY\", \"QUANTITY\", \"MEASUREMENT\"}\n",
        "        unit_keys = {\"UNIT\", \"UNIT PRICE\"}\n",
        "        tax_keys = {\"TAX\"}\n",
        "\n",
        "        def find_quantity_key(data):\n",
        "            for key in quantity_keys:\n",
        "                if key in data:\n",
        "                    return key  # Return the found key\n",
        "            return None\n",
        "\n",
        "        def find_unit_key(data):\n",
        "            for key in unit_keys:\n",
        "                if key in data:\n",
        "                    return key  # Return the found key\n",
        "            return None\n",
        "\n",
        "        for items in final_list:\n",
        "            for item in items:\n",
        "                description = item.get(\"DESCRIPTION\", \"\").strip()\n",
        "                qty_key = find_quantity_key(item)\n",
        "                unit_key = find_unit_key(item)\n",
        "                unitvalue = ''\n",
        "                unit_description = ''\n",
        "                quantity = item.get(qty_key, \"\").strip()\n",
        "                unit_value = item.get(unit_key, \"\").strip()\n",
        "                tax_value = item.get('TAX', \"\").strip()\n",
        "\n",
        "                match = quantity_pattern.search(quantity)\n",
        "                if match:\n",
        "                    extracted_quantity = match.group(\"quantity\") + \" \" + match.group(\"unit\")\n",
        "                    remaining_text = quantity.replace(match.group(0), \"\").strip()\n",
        "\n",
        "                    if not description:\n",
        "                        description = remaining_text\n",
        "                        quantity = extracted_quantity\n",
        "                    else:\n",
        "                        quantity = extracted_quantity\n",
        "                        description = description + \" \" + remaining_text if remaining_text else description\n",
        "\n",
        "                if unit_value:\n",
        "                    unit_pattern = re.match(r'^(.*?)(\\d+(?:\\.\\d+)?)?\\s*$', unit_value.strip())\n",
        "                    if unit_pattern:\n",
        "                        unit_description = unit_pattern.group(1).strip()\n",
        "                        value_str = unit_pattern.group(2)\n",
        "                        unitvalue = float(value_str) if value_str else None\n",
        "\n",
        "                if tax_value is not None:\n",
        "                    tax_pattern = re.match(r'^(.*?)(\\d+(?:\\.\\d+)?)?\\s*$', tax_value.strip())\n",
        "                    if tax_pattern:\n",
        "                        tax_description = tax_pattern.group(1).strip()\n",
        "                        value_str2 = tax_pattern.group(2)\n",
        "                        tax_value = float(value_str2) if value_str2 else None\n",
        "\n",
        "                if unit_description:\n",
        "                    description = description + ' ' + unit_description\n",
        "\n",
        "                if tax_description:\n",
        "                    description = description + ' ' + tax_description\n",
        "\n",
        "                item[\"DESCRIPTION\"] = description\n",
        "                item[qty_key] = quantity\n",
        "\n",
        "                if unitvalue:\n",
        "                    item[unit_key] = str(unitvalue)\n",
        "                #if tax_value:\n",
        "                item['TAX'] = str(tax_value)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return final_list\n",
        "\n",
        "def add_record_ids(data):\n",
        "    result = {}\n",
        "    count = 1\n",
        "    try:\n",
        "        for room, items in data.items():\n",
        "            result[room] = []\n",
        "            for idx, item in enumerate(items, 1):\n",
        "                new_item = item.copy()\n",
        "                new_item[\"record_id\"] = f\"{count}\"\n",
        "                count += 1\n",
        "                result[room].append(new_item)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return result\n",
        "\n",
        "def transform_construction_data22(data):\n",
        "    result = {}\n",
        "    current_section = []\n",
        "\n",
        "    for section in data:\n",
        "        section_name = None\n",
        "\n",
        "        try:\n",
        "            last_record = section[-1]\n",
        "            # Check if last_record has relevant keys\n",
        "            if any(key in last_record for key in [\"DESCRIPTION\", \"QUANTITY\", \"QTY\"]):\n",
        "                # Check if the last record is a total record\n",
        "                if any(\"Total:\" in (last_record.get(key) or \"\") or \"Totals:\" in (last_record.get(key) or \"\")\n",
        "                       for key in [\"DESCRIPTION\", \"QUANTITY\"]):\n",
        "\n",
        "                    section_name = \"Unknown Section\"\n",
        "\n",
        "                    try:\n",
        "                        # If no valid name in DESCRIPTION, check QUANTITY\n",
        "                        if section_name == \"Unknown Section\" and \"QUANTITY\" in last_record and isinstance(last_record[\"QUANTITY\"], str):\n",
        "                            qty_clean = last_record[\"QUANTITY\"].replace(\"Totals:\", \"\").replace(\"Total:\", \"\").strip()\n",
        "                            #print('qty clean '+ qty_clean)\n",
        "                            if qty_clean:\n",
        "                                section_name = qty_clean\n",
        "\n",
        "                        # Extract section name from DESCRIPTION if valid\n",
        "                        if section_name == \"Unknown Section\" and \"DESCRIPTION\" in last_record and isinstance(last_record[\"DESCRIPTION\"], str):\n",
        "                            desc_clean = last_record[\"DESCRIPTION\"].replace(\"Totals:\", \"\").replace(\"Total:\", \"\").strip()\n",
        "                            #print('desc  clean '+ desc_clean)\n",
        "                            if desc_clean and len(desc_clean.split()) <= 5:  # Ensure it's not a full sentence\n",
        "                                section_name = desc_clean\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error extracting section name: {e}\")\n",
        "\n",
        "                    # Print debug information\n",
        "                    print(f\"Section Name Identified: {section_name}\")\n",
        "\n",
        "                    # Store pending records before starting new section\n",
        "                    if current_section:\n",
        "                        if section_name not in result:\n",
        "                            result[section_name] = []\n",
        "                        result[section_name].extend(current_section)\n",
        "                        current_section = []\n",
        "\n",
        "                    # Store current section's records except last (total record)\n",
        "                    if section_name not in result:\n",
        "                        result[section_name] = []\n",
        "                    result[section_name].extend(section[:-1])\n",
        "\n",
        "                else:\n",
        "                    # If no total record, accumulate records in current_section\n",
        "                    current_section.extend(section)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(traceback.format_exc())\n",
        "            print(f\"Exception occurred: {e}\")\n",
        "\n",
        "    # Assign any remaining records to the last section\n",
        "    if current_section and result:\n",
        "        last_section = list(result.keys())[-1]\n",
        "        result[last_section].extend(current_section)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def transform_construction_data2(data):\n",
        "    result = {}\n",
        "    current_section = []\n",
        "\n",
        "    KEY_VARIANTS = {\n",
        "        'quantity': ['quantity', 'qty'],\n",
        "        'unit': ['unit', 'unit price'],\n",
        "        'tax': ['tax', 'tax percent', 'tax value']\n",
        "    }\n",
        "\n",
        "    def find_flexible_key(item, standard_key):\n",
        "        \"\"\"Find the key in `item` that matches any known variant for the given standard key.\"\"\"\n",
        "        variants = KEY_VARIANTS.get(standard_key, [])\n",
        "        for var in variants:\n",
        "            for key in item:\n",
        "                if var.lower() in key.lower():\n",
        "                    return key\n",
        "        return None\n",
        "\n",
        "    def is_non_numeric_string(value):\n",
        "        try:\n",
        "            float(value)\n",
        "            return False  # It's numeric (even if in string form)\n",
        "        except (ValueError, TypeError):\n",
        "            return isinstance(value, str)\n",
        "\n",
        "    for section in data:\n",
        "        section_name = None\n",
        "\n",
        "        try:\n",
        "            last_record = section[-1]\n",
        "            # Check if last_record has relevant keys\n",
        "            if any(key in last_record for key in [\"DESCRIPTION\", \"QUANTITY\", \"QTY\"]):\n",
        "                #print(last_record)\n",
        "                qty_key = find_flexible_key(last_record, 'quantity')\n",
        "                unit_key = find_flexible_key(last_record, 'unit')\n",
        "\n",
        "                # Check if the last record is a total record\n",
        "                if any(\"Total:\" in (last_record.get(key) or \"\") or \"Totals:\" in (last_record.get(key) or \"\")\n",
        "                       for key in [\"DESCRIPTION\", \"QUANTITY\", \"QTY\"]):\n",
        "\n",
        "                    section_name = \"Unknown Section\"\n",
        "\n",
        "                    try:\n",
        "                        # If no valid name in DESCRIPTION, check QUANTITY\n",
        "                        if section_name == \"Unknown Section\" and qty_key in last_record and isinstance(last_record[qty_key], str):\n",
        "                            #print('in one')\n",
        "                            desc_clean = last_record[\"DESCRIPTION\"].replace(\"Totals:\", \"\").replace(\"Total:\", \"\").strip()\n",
        "                            qty_clean = last_record[qty_key].replace(\"Totals:\", \"\").replace(\"Total:\", \"\").strip()\n",
        "                            unit_value = last_record.get(unit_key, '').strip()\n",
        "                            unit_type = is_non_numeric_string(unit_value)\n",
        "                            #print('desc clean '+ desc_clean)\n",
        "                            #print('qty clean' + qty_clean)\n",
        "                            #print('unit value ' + unit_value)\n",
        "\n",
        "                            if desc_clean:\n",
        "                                section_name = desc_clean\n",
        "                            if qty_clean:\n",
        "                                if section_name != 'Unknown Section':\n",
        "                                    section_name = section_name + ' ' + qty_clean\n",
        "                                else:\n",
        "                                    section_name = qty_clean\n",
        "                            if unit_type and unit_value:\n",
        "                                if section_name != 'Unknown Section':\n",
        "                                    section_name = section_name + ' ' + unit_value\n",
        "                                else:\n",
        "                                    section_name = unit_value\n",
        "\n",
        "\n",
        "                        # Extract section name from DESCRIPTION if valid\n",
        "                        if section_name == \"Unknown Section\" and \"DESCRIPTION\" in last_record and isinstance(last_record[\"DESCRIPTION\"], str):\n",
        "                            desc_clean = last_record[\"DESCRIPTION\"].replace(\"Totals:\", \"\").replace(\"Total:\", \"\").strip()\n",
        "                            qty_value = last_record.get(qty_key, '').strip()\n",
        "                            qty_type = is_non_numeric_string(qty_value)\n",
        "                            unit_value = last_record.get(unit_key, '').strip()\n",
        "                            unit_type = is_non_numeric_string(unit_value)\n",
        "\n",
        "                            if desc_clean and len(desc_clean.split()) <= 5:  # Ensure it's not a full sentence\n",
        "                                section_name = desc_clean\n",
        "                            if qty_type and qty_value:\n",
        "                                if section_name != 'Unknown Section':\n",
        "                                    section_name = section_name + ' ' + qty_value\n",
        "                                else:\n",
        "                                    section_name = qty_value\n",
        "                            if unit_type and unit_value:\n",
        "                                if section_name != 'Unknown Section':\n",
        "                                    section_name = section_name + ' ' + unit_value\n",
        "                                else:\n",
        "                                    section_name = unit_value\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error extracting section name: {e}\")\n",
        "\n",
        "                    # Print debug information\n",
        "                    print(f\"Section Name Identified: {section_name}\")\n",
        "                    # Store pending records before starting new section\n",
        "                    if current_section:\n",
        "                        if section_name not in result:\n",
        "                            result[section_name] = []\n",
        "                        result[section_name].extend(current_section)\n",
        "                        current_section = []\n",
        "\n",
        "                    # Store current section's records except last (total record)\n",
        "                    if section_name not in result:\n",
        "                        result[section_name] = []\n",
        "                    result[section_name].extend(section[:-1])\n",
        "\n",
        "                else:\n",
        "                    # If no total record, accumulate records in current_section\n",
        "                    current_section.extend(section)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(traceback.format_exc())\n",
        "            print(f\"Exception occurred: {e}\")\n",
        "\n",
        "    # Assign any remaining records to the last section\n",
        "    if current_section and result:\n",
        "        last_section = list(result.keys())[-1]\n",
        "        result[last_section].extend(current_section)\n",
        "\n",
        "    return result\n",
        "\n",
        "import traceback\n",
        "def PrettyPrintTablesTextract(textract_json):\n",
        "    df = None\n",
        "    #table_count = 0\n",
        "    tdoc = Document(textract_json)\n",
        "    final_list = []\n",
        "    quantity_keys = {\"QTY\", \"QUANTITY\", \"MEASUREMENT\"}\n",
        "\n",
        "    def find_QTY_key(d):\n",
        "        \"\"\"Find the key in the dictionary that matches QTY, QUANTITY, or MEASUREMENT.\"\"\"\n",
        "        for key in d:\n",
        "            if key.upper() in quantity_keys:\n",
        "                return key\n",
        "        return None  # No matching key found\n",
        "    def starts_with_integer(text):\n",
        "        return bool(re.match(r'^\\d+', text.strip())) if text else False\n",
        "\n",
        "    def remove_unwanted_description(converted_data):\n",
        "        try:\n",
        "            converted_data_output = []\n",
        "            for item in converted_data:\n",
        "                if starts_with_integer(item.get('DESCRIPTION', '').strip()):\n",
        "                    converted_data_output.append(item)\n",
        "                else:\n",
        "\n",
        "                    if item.get('DESCRIPTION', ''):\n",
        "                        if ('Total:' or 'Totals:') in item.get('DESCRIPTION', ''):\n",
        "                            converted_data_output.append(item)\n",
        "                        #else:\n",
        "                        #    print('in else')\n",
        "                        #    print('removed '+ str(item))\n",
        "                    else:\n",
        "                        #print('in description empty')\n",
        "                        if starts_with_integer(item.get('QUANTITY', '').strip()):\n",
        "                            converted_data_output.append(item)\n",
        "                        else:\n",
        "                            if 'Total:' in item.get('QUANTITY', '') or 'Totals:' in item.get('QUANTITY', ''):\n",
        "                                converted_data_output.append(item)\n",
        "                            #else:\n",
        "                            #    print('in else21')\n",
        "\n",
        "                            #    print('removed21 '+ str(item))\n",
        "\n",
        "            return converted_data_output\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(traceback.format_exc())\n",
        "            return converted_data\n",
        "\n",
        "    for page in tdoc.pages:\n",
        "        for table in page.tables:\n",
        "            desc_exist = True\n",
        "            #table_count += 1\n",
        "            df = pd.DataFrame(convert_table_to_list(trp_table=table))\n",
        "            #display(df)\n",
        "            json_data = df.to_json(orient='records')\n",
        "            json_data1 = json.loads(json_data)\n",
        "            headers = list(json_data1[0].values())\n",
        "            #print(headers)\n",
        "            headers = [header.strip().upper() for header in headers]\n",
        "            #print(headers)\n",
        "            QTY_key = find_QTY_key(headers)\n",
        "            #print('QTY_key ' + str(QTY_key))\n",
        "\n",
        "            if QTY_key not in headers:\n",
        "                #print('in not in headers')\n",
        "                # quantity_row_idx = df[df.isin([\"QUANTITY \", \"QTY \", \"MEASUREMENT \"]).any(axis=1)].index.min()\n",
        "                # quantity_row_idx = df[df.astype(str).apply(lambda x: x.str.upper()).isin([\"QUANTITY \", \"QTY \", \"MEASUREMENT \"]).any(axis=1)].index.min()\n",
        "                quantity_row_idx = df[df.astype(str).apply(lambda x: x.str.upper().str.strip()).isin(\n",
        "                    [\"QUANTITY\", \"QTY\", \"MEASUREMENT\"]).any(axis=1)].index.min()\n",
        "\n",
        "                if pd.notna(quantity_row_idx):\n",
        "                    df = df.drop(index=0).reset_index(drop=True)\n",
        "                    json_data = df.to_json(orient='records')\n",
        "                    json_data1 = json.loads(json_data)\n",
        "                    headers = list(json_data1[0].values())\n",
        "\n",
        "            headers = [header.strip().upper() for header in headers]\n",
        "            #print(headers)\n",
        "\n",
        "            totals_row_idx = None\n",
        "\n",
        "            patterns = [r'(?i)^total:', r'(?i)^totals:', r'(?i)total:\\s', r'(?i)totals:\\s']\n",
        "            # Check each row for the patterns\n",
        "            for idx, row in df.iterrows():\n",
        "                for col in row.index:\n",
        "                    cell_value = str(row[col]).strip()\n",
        "                    # Check if cell contains \"Total:\" or \"Totals:\"\n",
        "                    if any(pd.Series(cell_value).str.contains(pattern, regex=True).any() for pattern in\n",
        "                           patterns):\n",
        "                        if totals_row_idx is None or idx < totals_row_idx:\n",
        "                            totals_row_idx = idx\n",
        "\n",
        "            # If a \"Total:\" or \"Totals:\" row was found, remove all rows after it\n",
        "            if totals_row_idx is not None:\n",
        "                df = df.loc[:totals_row_idx].copy()\n",
        "            json_data = df.to_json(orient='records')\n",
        "            json_data1 = json.loads(json_data)\n",
        "            #print('#' * 100 + str(' after remove totals below'))\n",
        "            #print(df)\n",
        "\n",
        "            table_data = json_data1[1:]\n",
        "            if headers[0] == '':\n",
        "                headers[0] = 'DESCRIPTION'\n",
        "                desc_exist = False\n",
        "            elif headers[0] != 'DESCRIPTION':\n",
        "                desc_exist = False\n",
        "                table_data = []\n",
        "                headers.insert(0, 'DESCRIPTION')\n",
        "                for item in json_data1[1:]:\n",
        "                    new_item = {'0': ''}  # Add new empty key '0'\n",
        "\n",
        "                    # Shift all existing keys up by 1\n",
        "                    for key, value in item.items():\n",
        "                        new_key = str(int(key) + 1)  # Convert to int, add 1, then back to str\n",
        "                        new_item[new_key] = value\n",
        "\n",
        "                    table_data.append(new_item)\n",
        "\n",
        "            #print('after added ' + str(headers))\n",
        "\n",
        "            converted_data = []\n",
        "            for row in table_data:\n",
        "                # Ignore rows that don't have valid numbers in relevant fields\n",
        "                if 'REPLACE' in headers:\n",
        "                    if not any(row.get(str(i), \"\").strip().replace(\",\", \"\").replace(\".\", \"\").isdigit() for i in\n",
        "                               range(1, 8)):\n",
        "                        continue\n",
        "                if ('DESCRIPTION' in headers) and any(h in headers for h in ['QTY', 'MEASUREMENT', 'QUANTITY']) \\\n",
        "                        and any(h in headers for h in ['UNIT', 'PRICE', \"UNIT PRICE\", 'REPLACE']):\n",
        "                    #print('in if condition success')\n",
        "                    converted_data.append(\n",
        "                        {headers[i].strip(): row.get(str(i), \"\").strip() for i in range(len(headers))})\n",
        "\n",
        "            converted_data = [item for item in converted_data if item != {'': ''}]\n",
        "            # converted_data = [{k: v for k, v in item.items() if v.strip() != \"\"} for item in converted_data]\n",
        "            if converted_data:\n",
        "                print(df)\n",
        "\n",
        "            total_entries = len(converted_data)\n",
        "            qty_starting_with_int = 0\n",
        "            #print('cd ' + str(converted_data))\n",
        "            count_starting_with_int = sum(\n",
        "                1 for item in converted_data\n",
        "                if starts_with_integer(item.get('DESCRIPTION', ''))\n",
        "            )\n",
        "            if count_starting_with_int == 0:\n",
        "                desc_exist = sum(1 for item in converted_data if item.get('DESCRIPTION', ''))\n",
        "                if not desc_exist:\n",
        "                    qty_starting_with_int = sum(\n",
        "                        1 for item in converted_data\n",
        "                        if starts_with_integer(item.get('QUANTITY', ''))\n",
        "                    )\n",
        "            if qty_starting_with_int:\n",
        "                converted_data = remove_unwanted_description(converted_data)\n",
        "            #print('cd3 ' + str(converted_data))\n",
        "            #print('integer '+ str(count_starting_with_int))\n",
        "            try:\n",
        "                if converted_data and count_starting_with_int:\n",
        "                    if 'ACV' in converted_data[0].keys():\n",
        "                        #print('in if')\n",
        "                        percentage_with_description1 = (count_starting_with_int / total_entries) * 100\n",
        "                        #print('in '+ str(percentage_with_description1))\n",
        "                        if percentage_with_description1 >= 20:\n",
        "                            converted_data = remove_unwanted_description(converted_data)\n",
        "                    else:\n",
        "                        print('in elseeee')\n",
        "            except:\n",
        "                print('in except')\n",
        "                print(traceback.format_exc())\n",
        "                pass\n",
        "\n",
        "            #print('cd2 ' + str(converted_data))\n",
        "            final_list2 = []\n",
        "            if converted_data:\n",
        "                #print(desc_exist)\n",
        "                #print(converted_data)\n",
        "                if desc_exist == False:\n",
        "                    #print('###########2 converted data' + str(converted_data))\n",
        "\n",
        "                    # Count entries with non-empty descriptions\n",
        "                    non_empty_descriptions = sum(1 for item in converted_data if item.get('ACV'))\n",
        "                    # Calculate percentage\n",
        "                    percentage_with_description = (non_empty_descriptions / total_entries) * 100\n",
        "                    #print('pwd '+str(percentage_with_description))\n",
        "                    if percentage_with_description <= 90:\n",
        "                        #final_list2 = merge_entries(converted_data)\n",
        "                        final_list2 = merge_and_clean_data(converted_data)\n",
        "                    else:\n",
        "                        #print('cd2 ' + str(converted_data))\n",
        "                        final_list2 = converted_data\n",
        "                else:\n",
        "                    #print('in else')\n",
        "                    # Example usage:\n",
        "                    final_list2 = merge_entries(converted_data)\n",
        "                #print(final_list2)\n",
        "\n",
        "                final_list.append(final_list2)\n",
        "            #print('#' * 50)\n",
        "        # print(final_list)\n",
        "    return final_list\n",
        "\n",
        "\n",
        "final_list = PrettyPrintTablesTextract(textract_json_cic_full_insurance)\n",
        "#print('#' * 100)\n",
        "#print(json.dumps(final_list, indent=4))\n",
        "#print('final list')\n",
        "\n",
        "#print(final_list)\n",
        "#print('#' * 100)\n",
        "\n",
        "final_list = process_items(final_list)  # qa\n",
        "\n",
        "results1 = transform_construction_data2(final_list)  # qa\n",
        "results1 = {key: value for key, value in results1.items() if value}  # qa\n",
        "\n",
        "\n",
        "results1 = clean_description(results1)  # qa\n",
        "print(json.dumps(results1, indent=4))\n",
        "#print(results1.indent(4))\n",
        "#results3 = compare_and_get_unique_keys(results1, results2)\n",
        "#print(results3)\n",
        "\n",
        "#results2 = compare_json(results1, results2)\n",
        "\n",
        "#results2 = add_record_ids(results2)\n",
        "\n",
        "\n",
        "#print(results1)\n",
        "#print(results2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "rjcmRSApfYlH",
        "outputId": "14cc901e-7ab5-43f0-9c3a-c1d0bec77c8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "S3UploadFailedError",
          "evalue": "Failed to upload /content/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf to awstextractpdfuploads/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf: An error occurred (AuthorizationHeaderMalformed) when calling the PutObject operation: The authorization header is malformed; a non-empty Access Key (AKID) must be provided in the credential.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;31m# If a client error was raised, add the backwards compatibility layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# out of this and propagate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_execute_main\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;31m# If the task is the final task, then set the TransferFuture's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3transfer/upload.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, client, fileobj, bucket, key, extra_args)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botocore/context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: An error occurred (AuthorizationHeaderMalformed) when calling the PutObject operation: The authorization header is malformed; a non-empty Access Key (AKID) must be provided in the credential.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mS3UploadFailedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0c6c6bc1e6a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0ms3bucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'awstextractpdfuploads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0ms3_uri_of_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"s3://awstextractpdfuploads/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mbucket_upload_file\u001b[0;34m(self, Filename, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mtransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m     return self.meta.client.upload_file(\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botocore/context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \"\"\"\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mS3Transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         return transfer.upload_file(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# client error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             raise S3UploadFailedError(\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \"Failed to upload {} to {}: {}\".format(\n\u001b[1;32m    380\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mS3UploadFailedError\u001b[0m: Failed to upload /content/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf to awstextractpdfuploads/FINALDRAFTWITHAGELIFEANDCONDITIONReport32825_66.pdf: An error occurred (AuthorizationHeaderMalformed) when calling the PutObject operation: The authorization header is malformed; a non-empty Access Key (AKID) must be provided in the credential."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Prompting_REST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}